{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "982d74cc-dfe1-4a33-bc97-5638a8db97e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "2023-09-14 16:39:16.405523: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-14 16:39:17.840580: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import itertools\n",
    "import random\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "from sklearn.svm import OneClassSVM, SVC\n",
    "from sklearn.linear_model import SGDOneClassSVM, SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_recall_fscore_support, roc_curve\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras import regularizers\n",
    "import joblib\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f3e8376-f76e-4fef-b724-e683e2f0f651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_d = {}\n",
    "\n",
    "def datetime_to_timestamp(dt):\n",
    "    try:\n",
    "        return datetime.strptime(dt, '%m/%d/%Y %H:%M').weekday()\n",
    "    except:\n",
    "        return datetime.strptime(dt, '%Y-%m-%d %H:%M:%S').weekday()\n",
    "    \n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df = df.dropna()\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "def train_test_dataset(df_train, df_test, deep=True):\n",
    "    labelencoder = LabelEncoder()\n",
    "\n",
    "    X_train = df_train.drop(columns=['Label']).copy()\n",
    "    y_train = df_train.iloc[:, -1].values.reshape(-1,1).copy()\n",
    "    y_train = np.ravel(y_train).copy()\n",
    "    if deep:\n",
    "        y_train = to_categorical(y_train)\n",
    "    \n",
    "    if df_test is not None:\n",
    "        X_test = df_test.drop(columns=['Label']) .copy()\n",
    "        y_test = df_test.iloc[:, -1].values.reshape(-1,1).copy()\n",
    "        y_test = np.ravel(y_test).copy()\n",
    "        if deep:\n",
    "            y_test = to_categorical(y_test)\n",
    "\n",
    "        return  X_train, X_test, y_train, y_test\n",
    "    \n",
    "    else:\n",
    "        return train_test_split(X_train, y_train)\n",
    "    \n",
    "def show_cm(cm):\n",
    "    f,ax=plt.subplots(figsize=(5,5))\n",
    "    sns.heatmap(cm,annot=True,linewidth=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "    plt.xlabel(\"y_pred\")\n",
    "    plt.ylabel(\"y_true\")\n",
    "    plt.show()\n",
    "\n",
    "def from_categorical(y_):\n",
    "    return np.array([np.argmax(i) for i in y_])\n",
    "\n",
    "def discretize(a):\n",
    "    return 1 if a > 0.5 else 0\n",
    "\n",
    "def labels_to_numbers(df: pd.DataFrame, name='Label'):\n",
    "    labels = df[name].unique()\n",
    "    d = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "    return d\n",
    "\n",
    "def number_to_label(df, number, name='Label'):\n",
    "    labels = df[name].unique()\n",
    "    d = {idx: label for idx, label in enumerate(labels)}\n",
    "    return d[number]\n",
    "        \n",
    "\n",
    "def prepare_df(df: pd.DataFrame, dropcols=None, scaler=None, ldict=None):\n",
    "    temp_df = df.copy()\n",
    "    if dropcols:\n",
    "        temp_df = temp_df.drop(columns=dropcols)\n",
    "    if not ldict:\n",
    "        ltn_dict = labels_to_numbers(temp_df)\n",
    "    else:\n",
    "        ltn_dict = ldict\n",
    "    temp_df['Label'] = temp_df['Label'].map(ltn_dict)\n",
    "        \n",
    "    temp_df = clean_dataset(temp_df)\n",
    "    if scaler == 'minmax':\n",
    "        scaler = joblib.load('models/scaler.pkl')\n",
    "        # scaler = MinMaxScaler()\n",
    "    elif scaler == 'standard':\n",
    "        scaler = joblib.load('models/standard_scaler.pkl')\n",
    "        # scaler = StandardScaler()\n",
    "        \n",
    "    if scaler:\n",
    "        temp_df[temp_df.columns[:-1]] = scaler.fit_transform(temp_df[temp_df.columns[:-1]])\n",
    "        # joblib.dump(scaler, 'models/standard_scaler.pkl')\n",
    "    \n",
    "    return temp_df\n",
    "\n",
    "def binarize_label(y, label):\n",
    "    idx = y == label\n",
    "    \n",
    "    y[idx] = 1\n",
    "    y[~idx] = 0\n",
    "    \n",
    "def evaluate_model(model, df, binarize=None):\n",
    "    X = df.drop(columns=['Label']).copy()\n",
    "    y = df.iloc[:, -1].values.reshape(-1,1).copy()\n",
    "    y = np.ravel(y).copy()\n",
    "    if binarize is not None:\n",
    "        binarize_label(y, binarize)\n",
    "    \n",
    "    model.evaluate(X, y)\n",
    "    \n",
    "    y_predicted = model.predict(X)\n",
    "    cm = confusion_matrix(y, vdiscretize(y_predicted))\n",
    "    show_cm(cm)\n",
    "    \n",
    "def unsup_compare_results(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    return f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "def plot_cm(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    show_cm(cm)\n",
    "    \n",
    "def make_binary_svm(train, test, l):\n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_dataset(train, test, deep=False)\n",
    "    binarize_label(_y_train, l)\n",
    "    binarize_label(_y_test, l)\n",
    "    # _y_train[_y_train == 0] = -1\n",
    "    # _y_train[_y_train == 0] = -1\n",
    "    return _X_train, _X_test, _y_train, _y_test\n",
    "\n",
    "def check_all_labels(train, test, model_constructor, l_name='Label', constructor_kwargs=None):\n",
    "    labels = train[l_name].unique()\n",
    "    for label in labels:\n",
    "        print(f'============= Label {number_to_label(clean_test, label)} ==================')\n",
    "        X_train, X_test, y_train, y_test = make_binary_svm(clean_train, clean_test, label)\n",
    "        if constructor_kwargs:\n",
    "            model = model_constructor(**constructor_kwargs)\n",
    "        else:\n",
    "            model = model_constructor()\n",
    "        model.fit(X_train, y_train)\n",
    "        print(unsup_compare_results(model, X_test, y_test))\n",
    "        probs = model.predict_proba(X_test)[:, 1]\n",
    "        plot_roc(y_test, probs)\n",
    "        \n",
    "    \n",
    "def plot_roc(y, probs, label='Classifier'):\n",
    "    ns_probs = [0 for _ in range(len(y))]\n",
    "    \n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y, ns_probs)\n",
    "    fpr, tpr, _ = roc_curve(y, probs)\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "    plt.plot(fpr, tpr, label=label)\n",
    "    # plt.ylim([0.0, 1.05])\n",
    "    # plt.xlim([0.0, 1.05])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "        \n",
    "vdiscretize = np.vectorize(discretize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec4adf59-1766-4b12-b61c-941579e4ae31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set_path = 'Training.csv'\n",
    "test_set_path = 'Testing.csv'\n",
    "\n",
    "training_df = pd.read_csv(training_set_path)\n",
    "test_df = pd.read_csv(test_set_path)\n",
    "\n",
    "\n",
    "# clean_train = prepare_df(training_df, dropcols=['Flow ID', 'Src IP', 'Dst IP', 'Dst Port', 'Src Port', 'Protocol', 'Timestamp'], scaler='minmax')\n",
    "# clean_test = prepare_df(test_df, dropcols=['Flow ID', 'Src IP', 'Dst IP', 'Dst Port', 'Src Port', 'Protocol', 'Timestamp'], scaler='minmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46847255-ee52-4878-aa82-dfabc86a1006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = 'standard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "250345e5-baf7-4bb4-835f-3cb83841e3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3066/3959412877.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n",
      "  indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
      "/tmp/ipykernel_3066/3959412877.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n",
      "  indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
      "/tmp/ipykernel_3066/3959412877.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n",
      "  indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n"
     ]
    }
   ],
   "source": [
    "clean_train = prepare_df(training_df, dropcols=['Flow ID', 'Src IP', 'Dst IP', 'Dst Port', 'Src Port', 'Protocol', 'Timestamp'], scaler=scaler)\n",
    "clean_test = prepare_df(test_df, dropcols=['Flow ID', 'Src IP', 'Dst IP', 'Dst Port', 'Src Port', 'Protocol', 'Timestamp'], scaler=scaler)\n",
    "X_train_scvic, X_test_scvic, y_train_scvic, y_test_scvic = make_binary_svm(clean_train, clean_test, 0)\n",
    "\n",
    "\n",
    "frames = []\n",
    "for file in os.listdir(\"./dapt2020/csv/\"):\n",
    "    if file.endswith(\".csv\"):\n",
    "        path = \"./dapt2020/csv/\" + file\n",
    "        tmp = pd.read_csv(path)\n",
    "        frames.append(tmp)\n",
    "        \n",
    "        \n",
    "dapt2020 = pd.concat(frames)\n",
    "dapt2020 = dapt2020.rename(columns={\"Stage\": \"Label\"})\n",
    "# dapt2020 = pd.concat(frames)\n",
    "\n",
    "dapt_label_d = {\n",
    "    \"Benign\": 0,\n",
    "    'BENIGN': 0,\n",
    "    'Establish Foothold': 1,\n",
    "    'Reconnaisance': 2,\n",
    "    'Data Exfiltration': 5,\n",
    "    'Lateral Movement': 4\n",
    "}\n",
    "\n",
    "clean_dapt = prepare_df(dapt2020, dropcols=['Flow ID', 'Src IP', 'Dst IP', 'Dst Port', 'Src Port', 'Protocol', 'Timestamp', 'Activity'], scaler=scaler, ldict=dapt_label_d)\n",
    "\n",
    "X_train_dapt, X_test_dapt, y_train_dapt, y_test_dapt = make_binary_svm(clean_dapt, None, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "625be381-8cb1-4f02-8db4-408e5c8ae257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00209644 0.88658566]\n"
     ]
    }
   ],
   "source": [
    "# SCIVC -> DAPT\n",
    "svm = SGDClassifier(loss='hinge', alpha=0.0001, max_iter=1000, tol=1e-2)\n",
    "\n",
    "svm.fit(X_train_scvic, y_train_scvic)\n",
    "\n",
    "print(unsup_compare_results(svm, X_test_dapt, y_test_dapt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "140597f2-e4b4-4693-89cd-38f8ac309e77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.004641588833612777, 'loss': 'hinge', 'max_iter': 10, 'tol': 0.1}\n"
     ]
    }
   ],
   "source": [
    "sgdc = SGDClassifier()\n",
    "\n",
    "sgdc_params = {\n",
    "    'loss':['hinge'],\n",
    "    'max_iter':[10,100,1000],\n",
    "    'alpha':np.logspace(-3, 3, 10),\n",
    "    'tol': np.logspace(-3, 3, 10),\n",
    "}\n",
    "\n",
    "\n",
    "sgdc_gs = GridSearchCV(sgdc, sgdc_params, verbose=1, n_jobs=-1)\n",
    "\n",
    "sgdc_gs.fit(X_train_scvic, y_train_scvic)\n",
    "\n",
    "print(sgdc_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e65b59c-477d-4d72-9b48-c8d2069e9891",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100, 'tol': 2.154434690031882}\n"
     ]
    }
   ],
   "source": [
    "sgdc = SGDClassifier()\n",
    "\n",
    "sgdc_params = {\n",
    "    'loss':['hinge'],\n",
    "    'max_iter':[10,100,1000],\n",
    "    'alpha':np.logspace(-5, 5, 10),\n",
    "    'tol': np.logspace(-3, 3, 10),\n",
    "}\n",
    "\n",
    "\n",
    "sgdc_gs = GridSearchCV(sgdc, sgdc_params, verbose=1, n_jobs=-1)\n",
    "\n",
    "sgdc_gs.fit(X_train_dapt, y_train_dapt)\n",
    "\n",
    "print(sgdc_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "466a97aa-3c24-4a1e-8d10-049d0bb791ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00001, 0.00013, 0.00167, 0.02154, 0.27826, 3.59381, 46.41589, 599.48425, 7742.63683, 100000.00000, "
     ]
    }
   ],
   "source": [
    "for i in np.logspace(-5, 5, 10):\n",
    "    print(f\"{i:.5f}\", end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f85c8ae0-f34d-45c0-9497-292fef09bf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80326838 0.99716133]\n",
      "[0.00187135 0.87115379]\n"
     ]
    }
   ],
   "source": [
    "# SCIVC -> DAPT\n",
    "svm = SGDClassifier(alpha=0.00001, loss='hinge', max_iter=1000, tol=0.1)\n",
    "\n",
    "svm.fit(X_train_scvic, y_train_scvic)\n",
    "\n",
    "print(unsup_compare_results(svm, X_test_scvic, y_test_scvic))\n",
    "print(unsup_compare_results(svm, X_test_dapt, y_test_dapt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4ddced8-1139-4302-ad2d-9a40fac18af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78057209 0.96448436]\n",
      "[0.01119795 0.91792295]\n"
     ]
    }
   ],
   "source": [
    "# DAPT -> SCIVC\n",
    "svm = SGDClassifier(alpha=0.001, loss='hinge', max_iter=100, tol=2.1544)\n",
    "\n",
    "svm.fit(X_train_dapt, y_train_dapt)\n",
    "\n",
    "print(unsup_compare_results(svm, X_test_dapt, y_test_dapt))\n",
    "print(unsup_compare_results(svm, X_test_scvic, y_test_scvic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fd3cdb2-b7ea-4e19-bb0d-d5e7419d104e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00271739 0.86644833]\n"
     ]
    }
   ],
   "source": [
    "# SCIVC -> DAPT\n",
    "svm = SVC(kernel='rbf', C=10, gamma=0.001)\n",
    "\n",
    "svm.fit(X_train_scvic, y_train_scvic)\n",
    "\n",
    "print(unsup_compare_results(svm, X_test_dapt, y_test_dapt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dd1f385-a6cf-42f6-be84-a94876988598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88643362 0.98032694]\n"
     ]
    }
   ],
   "source": [
    "# DAPT -> SCVIC\n",
    "svm = SVC(kernel='rbf', C=100, gamma=1)\n",
    "\n",
    "svm.fit(X_train_dapt, y_train_dapt)\n",
    "\n",
    "print(unsup_compare_results(svm, X_test_dapt, y_test_dapt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df8b6d47-5886-400e-ae0c-6b49ca8399dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13275/3959412877.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n",
      "  indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
      "/tmp/ipykernel_13275/3959412877.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n",
      "  indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82520074 0.99743276]\n"
     ]
    }
   ],
   "source": [
    "clean_train = prepare_df(training_df, dropcols=['Flow ID', 'Src IP', 'Dst IP', 'Dst Port', 'Src Port', 'Protocol', 'Timestamp'], scaler=scaler)\n",
    "clean_test = prepare_df(test_df, dropcols=['Flow ID', 'Src IP', 'Dst IP', 'Dst Port', 'Src Port', 'Protocol', 'Timestamp'], scaler=scaler)\n",
    "\n",
    "X_train, X_test, y_train, y_test = make_binary_svm(clean_train, clean_test, 0)\n",
    "\n",
    "\n",
    "svm = SGDClassifier(loss='hinge', alpha=0.0001, max_iter=1000, tol=1e-2)\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print(unsup_compare_results(svm, X_test, y_test))\n",
    "\n",
    "# probs = svm.predict_proba(X_test)[:, 1]\n",
    "# plot_roc(y_test, probs, label='SGD SVM SCVIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82594d9e-e2c7-4aa3-a6ef-3e23d82c3c38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13275/3959412877.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n",
      "  indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74910394 0.96107507]\n"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "for file in os.listdir(\"./dapt2020/csv/\"):\n",
    "    if file.endswith(\".csv\"):\n",
    "        path = \"./dapt2020/csv/\" + file\n",
    "        tmp = pd.read_csv(path)\n",
    "        frames.append(tmp)\n",
    "        \n",
    "        \n",
    "dapt2020 = pd.concat(frames)\n",
    "dapt2020 = dapt2020.rename(columns={\"Stage\": \"Label\"})\n",
    "# dapt2020 = pd.concat(frames)\n",
    "\n",
    "dapt_label_d = {\n",
    "    \"Benign\": 0,\n",
    "    'BENIGN': 0,\n",
    "    'Establish Foothold': 1,\n",
    "    'Reconnaisance': 2,\n",
    "    'Data Exfiltration': 5,\n",
    "    'Lateral Movement': 4\n",
    "}\n",
    "\n",
    "clean_dapt = prepare_df(dapt2020, dropcols=['Flow ID', 'Src IP', 'Dst IP', 'Dst Port', 'Src Port', 'Protocol', 'Timestamp', 'Activity'], scaler=scaler, ldict=dapt_label_d)\n",
    "\n",
    "X_train, X_test, y_train, y_test = make_binary_svm(clean_dapt, None, 0)\n",
    "\n",
    "svm = SGDClassifier(loss='hinge', alpha=0.0001, max_iter=100, tol=1e-2)\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print(unsup_compare_results(svm, X_test, y_test))\n",
    "\n",
    "# probs = svm.predict_proba(X_test)[:, 1]\n",
    "# plot_roc(y_test, probs, label='SGD SVM DAPT2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40e4129d-dbbc-4a6b-8a69-a3718f348422",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79639175 0.99713514]\n",
      "[0.00263227 0.88720864]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = make_binary_svm(clean_train, clean_test, 0)\n",
    "\n",
    "\n",
    "svm = SGDClassifier(loss='hinge', alpha=0.0001, max_iter=100, tol=1e-2)\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print(unsup_compare_results(svm, X_test, y_test))\n",
    "\n",
    "# probs = svm.predict_proba(X_test)[:, 1]\n",
    "# plot_roc(y_test, probs, label='SGD SVM SCVIC')\n",
    "\n",
    "X_train, X_test, y_train, y_test = make_binary_svm(clean_dapt, None, 0)\n",
    "\n",
    "print(unsup_compare_results(svm, X_test, y_test))\n",
    "\n",
    "# probs = svm.predict_proba(X_test)[:, 1]\n",
    "# plot_roc(y_test, probs, label='SGD SVM cross dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55dd790d-9545-4847-95bf-f71cfdc8fd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# oc = OneClassSVM(kernel='linear', gamma=0.000001, nu=0.10)\n",
    "\n",
    "# oc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f7abfcd-d03e-4548-a871-1f2e25e07998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94060995 0.99899077]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = make_binary_svm(clean_train, clean_test, 0)\n",
    "\n",
    "svc = SVC(C=10, gamma=0.001, verbose=2, kernel='rbf')\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "print(unsup_compare_results(svc, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c0238b2-f901-4fcd-9082-4fbfd0df48ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88810931 0.98104829]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = make_binary_svm(clean_dapt, None, 0)\n",
    "\n",
    "svcdapt = SVC(C=100, gamma=1, kernel='rbf', verbose=2)\n",
    "\n",
    "svcdapt.fit(X_train, y_train)\n",
    "print(unsup_compare_results(svcdapt, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55380b7d-eeed-409b-9579-0daf39c43ead",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.99186127]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = make_binary_svm(clean_train, clean_test, 0)\n",
    "print(unsup_compare_results(svcdapt, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f424b4a-a94f-4e44-baad-77ef65fcb753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "# grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2, n_jobs=-1)\n",
    "# grid.fit(X_train,y_train)\n",
    "# print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91496c78-8e6f-4ae7-8b43-52d61481cdde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = make_binary_svm(clean_train, clean_test, 0)\n",
    "# param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001]}\n",
    "# grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=5, n_jobs=-1)\n",
    "# grid.fit(X_train,y_train)\n",
    "# print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e9d92510-7507-4fe7-8d9c-305853e59982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.06, NNZs: 69, Bias: 1.000268, T: 253028, Avg. loss: 0.000843\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.05, NNZs: 69, Bias: 0.998836, T: 506056, Avg. loss: 0.000150\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 69, Bias: 0.998421, T: 759084, Avg. loss: 0.000129\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 69, Bias: 1.001449, T: 1012112, Avg. loss: 0.000125\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.04, NNZs: 69, Bias: 0.998588, T: 1265140, Avg. loss: 0.000106\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.04, NNZs: 69, Bias: 0.998734, T: 1518168, Avg. loss: 0.000103\n",
      "Total training time: 0.43 seconds.\n",
      "Convergence after 6 epochs took 0.43 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.05887712, 0.78428959])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = make_binary_svm(clean_train, clean_test, 0)\n",
    "X_normal = X_train[y_train == 1]\n",
    "\n",
    "y_test[y_test == 0] = -1\n",
    "\n",
    "oc = SGDOneClassSVM(nu=0.10, verbose=2)\n",
    "oc.fit(X_normal)\n",
    "\n",
    "unsup_compare_results(oc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1671d9b2-9b54-48b2-bdef-cb7a1ec1fb31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.04, NNZs: 64, Bias: 1.016153, T: 47858, Avg. loss: 0.002225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 64, Bias: 1.006063, T: 95716, Avg. loss: 0.000282\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.03, NNZs: 64, Bias: 1.007595, T: 143574, Avg. loss: 0.000171\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 64, Bias: 1.003067, T: 191432, Avg. loss: 0.000106\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.01, NNZs: 64, Bias: 1.001772, T: 239290, Avg. loss: 0.000083\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.01, NNZs: 64, Bias: 1.001187, T: 287148, Avg. loss: 0.000067\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.01, NNZs: 64, Bias: 1.001502, T: 335006, Avg. loss: 0.000060\n",
      "Total training time: 0.10 seconds.\n",
      "Convergence after 7 epochs took 0.10 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01731245, 0.85347265])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = make_binary_svm(clean_dapt, None, 0)\n",
    "X_normal = X_train[y_train == 1]\n",
    "\n",
    "y_test[y_test == 0] = -1\n",
    "\n",
    "oc = SGDOneClassSVM(nu=0.10, verbose=2)\n",
    "oc.fit(X_normal)\n",
    "\n",
    "unsup_compare_results(oc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c10a501d-0250-4f82-94b6-2c6ff58df993",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be789fc9-339e-4981-8e17-b16fc57a1a6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]....\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 4867\n",
      "obj = 11423511.355342, rho = 4779.280953\n",
      "nSV = 4782, nBSV = 4781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.05928587, 0.87282553])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = make_binary_svm(clean_dapt, None, 0)\n",
    "X_normal = X_train[y_train == 1]\n",
    "\n",
    "y_test[y_test == 0] = -1\n",
    "\n",
    "oc = OneClassSVM(gamma=0.000001, nu=0.10, verbose=2)\n",
    "oc.fit(X_normal)\n",
    "\n",
    "unsup_compare_results(oc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9761b3-4097-419b-9083-68b3575ddb42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM].......................\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 23230\n",
      "obj = 319931472.983748, rho = 25293.583986\n",
      "nSV = 25303, nBSV = 25302\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = make_binary_svm(clean_train, clean_test, 0)\n",
    "X_normal = X_train[y_train == 1]\n",
    "\n",
    "y_test[y_test == 0] = -1\n",
    "\n",
    "oc = OneClassSVM(gamma=0.000001, nu=0.10, verbose=2)\n",
    "oc.fit(X_normal)\n",
    "\n",
    "unsup_compare_results(oc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c00d1-a28f-4131-a452-d18e5a3c340c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
